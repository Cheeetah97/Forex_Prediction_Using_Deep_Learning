{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from Functions import *\n",
    "import lightgbm as lgb\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "data_path = \"M:/Dissertation/Data/\"\n",
    "results_path = \"M:/Dissertation/Return_Prediction/Machine_Learning/Results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Data\n",
    "data = pd.read_csv(data_path+\"Forex_Data.csv\")\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"],format=\"%Y-%m-%d %H:00:00\")\n",
    "data = data.loc[(data.Date>='2016-01-01')&(data.Date<'2018-01-01')].reset_index(drop=True)\n",
    "\n",
    "for col in ['EUR/USD_T','EUR/GBP_T','GBP/USD_T','XAU/USD_T']:\n",
    "    data[col] = data[col.split('_')[0]+'_R']\n",
    "\n",
    "for col in ['EUR/USD_R','EUR/GBP_R','GBP/USD_R','XAU/USD_R']:\n",
    "    data[col] = data[col].shift(1)\n",
    "    \n",
    "data = data.dropna(subset=['EUR/USD_R','EUR/GBP_R','GBP/USD_R','XAU/USD_R'])\n",
    "data = data.sort_values(by=[\"Date\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape is:  (11678, 8)\n",
      "Y Shape is:  (11678, 4)\n",
      "Data Shape is:  (11678, 13)\n"
     ]
    }
   ],
   "source": [
    "# LGBM Data Prep\n",
    "FEATURES = list(data.drop(['Date','EUR/USD_T','EUR/GBP_T','GBP/USD_T','XAU/USD_T'],axis=1).columns)\n",
    "TARGETS = ['EUR/USD_T','EUR/GBP_T','GBP/USD_T','XAU/USD_T']\n",
    "\n",
    "x,y = data[FEATURES].to_numpy(),data[TARGETS].to_numpy()\n",
    "print(\"X Shape is: \",x.shape)\n",
    "print(\"Y Shape is: \",y.shape)\n",
    "print(\"Data Shape is: \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape is:  (11318, 8)\n",
      "Y Shape is:  (11318, 4)\n",
      "Data Shape is:  (11318, 13)\n"
     ]
    }
   ],
   "source": [
    "# Extracting Test Sets for Evaluation\n",
    "test_portions = []\n",
    "test_portions_x = []\n",
    "test_portions_y = []\n",
    "TEST_SIZE = 71\n",
    "TEST_PORTIONS = 5\n",
    "\n",
    "for portion in generate_test_portions(data,TEST_SIZE,TEST_PORTIONS):\n",
    "    test_portions.append(data.loc[portion,:].reset_index(drop=True))\n",
    "    test_portions_x.append(x[portion,:])\n",
    "    test_portions_y.append(y[portion,:])\n",
    "    \n",
    "    data = data.loc[~(data.index.isin(portion)),:]\n",
    "    x = np.delete(x,portion,axis=0)\n",
    "    y = np.delete(y,portion,axis=0)\n",
    "    \n",
    "train_data = data.reset_index(drop=True).copy()\n",
    "print(\"X Shape is: \",x.shape)\n",
    "print(\"Y Shape is: \",y.shape)\n",
    "print(\"Data Shape is: \",train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size: 9054 Valid size: 2264 Test size: 360\n",
      "### Validation MSE: 7.884903276349632e-07\n",
      "### Test MSE: 8.561681735864634e-07\n",
      "#########################\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size: 9054 Valid size: 2264 Test size: 360\n",
      "### Validation MSE: 8.048835444172296e-07\n",
      "### Test MSE: 8.593108315640608e-07\n",
      "#########################\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size: 9054 Valid size: 2264 Test size: 360\n",
      "### Validation MSE: 7.330231381890752e-07\n",
      "### Test MSE: 8.53376093802567e-07\n",
      "#########################\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size: 9055 Valid size: 2263 Test size: 360\n",
      "### Validation MSE: 7.92280085709623e-07\n",
      "### Test MSE: 8.535933646636935e-07\n",
      "#########################\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size: 9055 Valid size: 2263 Test size: 360\n",
      "### Validation MSE: 8.138000348464475e-07\n",
      "### Test MSE: 8.574075141330526e-07\n",
      "#########################\n",
      "\n",
      "\n",
      "#########################\n",
      "### Avg Validation MSE: 7.864954261594679e-07\n",
      "### Avg Test MSE: 8.559711955499674e-07\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "# Getting Train and Validation Sets for Training\n",
    "FOLDS = 5\n",
    "SELECTED_FOLDS = 5\n",
    "\n",
    "train_portions_x,train_portions_y,valid_portions_x,valid_portions_y = get_folds(x,y,train_data,FOLDS,SELECTED_FOLDS)\n",
    "\n",
    "valid_mses = []\n",
    "test_mses = []\n",
    "test_preds_all = pd.DataFrame()\n",
    "for fold in range(SELECTED_FOLDS):\n",
    "\n",
    "    # Scale Features\n",
    "    x_train = train_portions_x[fold]\n",
    "    x_valid = valid_portions_x[fold]\n",
    "    x_test = test_portions_x\n",
    "    x_train_scaled,x_valid_scaled,x_test_scaled = x_scaler(x_train,x_valid,x_test,TSScaler())\n",
    "\n",
    "    # Scale Targets\n",
    "    y_train = train_portions_y[fold]\n",
    "    y_valid = valid_portions_y[fold]\n",
    "    y_test = test_portions_y\n",
    "    y_train_scaled,y_valid_scaled,y_test_scaled = y_scaler(y_train,y_valid,y_test,TSScaler(range=(-1,1)))\n",
    "    \n",
    "    # Modelling\n",
    "    valid_pred = np.zeros(y_valid.shape)\n",
    "    test_pred = y_test_scaled.copy()\n",
    "\n",
    "    for t in range(y_train.shape[1]):\n",
    "        \n",
    "        # Defining Model\n",
    "        params = {'n_estimators': 225,\n",
    "                  'boosting_type': 'gbdt',\n",
    "                  'verbosity': -1,\n",
    "                  'objective': 'l2',\n",
    "                  'colsample_bytree': 0.9,\n",
    "                  'colsample_bynode': 0.1,\n",
    "                  'max_depth': 8,\n",
    "                  'learning_rate': 0.003647749926797374,\n",
    "                  'reg_lambda': 0.5,\n",
    "                  'num_leaves': 61,\n",
    "                  'n_jobs': -1,\n",
    "                  'seed': 42}\n",
    "\n",
    "        lgb_model = lgb.LGBMRegressor(**params)\n",
    "        \n",
    "        # Model Training\n",
    "        lgb_model.fit(x_train_scaled,y_train_scaled[:,t])\n",
    "\n",
    "        # Saving Predictions on Validation set\n",
    "        valid_pred[:,t] = lgb_model.predict(x_valid_scaled)\n",
    "\n",
    "        # Saving Predictions on Test set\n",
    "        for i in range(TEST_PORTIONS):\n",
    "            test_pred[i][:,t] = lgb_model.predict(x_test_scaled[i])\n",
    "    \n",
    "    # Loading Scaler Objects\n",
    "    with open('scaler_y.pkl','rb') as file:\n",
    "        y_scaler_obj = pickle.load(file)\n",
    "\n",
    "    # Validation Set Loss\n",
    "    valid_mse = []\n",
    "    valid_pred = y_scaler_obj.inverse_transform(valid_pred)\n",
    "    for i in range(valid_pred.shape[1]):\n",
    "        valid_mse.append(mean_squared_error(y_valid[:,i],valid_pred[:,i]))\n",
    "    valid_mses.append(np.mean(valid_mse))\n",
    "\n",
    "    # Predicting the Test Set\n",
    "    test_mse = []\n",
    "    test_pred_df = pd.DataFrame()\n",
    "    test_portions_copy = test_portions.copy()\n",
    "    for i in range(TEST_PORTIONS):\n",
    "        tp = y_scaler_obj.inverse_transform(test_pred[i])\n",
    "        tp = pd.DataFrame(tp,columns=['EUR/USD_P','EUR/GBP_P','GBP/USD_P','XAU/USD_P'])\n",
    "        test_portions_copy[i] = pd.concat([test_portions_copy[i],tp],axis=1)\n",
    "\n",
    "        # Saving Predictions\n",
    "        for col in [\"GBP/USD\",\"EUR/USD\",\"EUR/GBP\",\"XAU/USD\"]:\n",
    "            test_mse.append(mean_squared_error(test_portions_copy[i][col+'_T'],test_portions_copy[i][col+'_P']))\n",
    "            test_portions_copy[i][col+'_PP'] = (test_portions_copy[i][col+'_P']+1) * test_portions_copy[i][col]\n",
    "            test_portions_copy[i][col+'_PP'] = test_portions_copy[i][col+'_PP'].shift(1)\n",
    "\n",
    "        test_portions_copy[i][\"Portion\"] = i\n",
    "        test_pred_df = pd.concat([test_pred_df,test_portions_copy[i][['Date','Portion']+TARGETS+['EUR/USD_P','EUR/GBP_P','GBP/USD_P','XAU/USD_P']+['EUR/USD_PP','EUR/GBP_PP','GBP/USD_PP','XAU/USD_PP']+['EUR/USD','EUR/GBP','GBP/USD','XAU/USD']]])\n",
    "    test_mses.append(np.mean(test_mse))\n",
    "    test_preds_all = pd.concat([test_preds_all,test_pred_df])\n",
    "\n",
    "    print('#' * 25)\n",
    "    print('### Fold', fold + 1)\n",
    "    print('### Train size:', len(x_train_scaled), 'Valid size:', len(x_valid_scaled), 'Test size:', len(x_test_scaled[0])*TEST_PORTIONS)\n",
    "    print('### Validation MSE:', np.mean(valid_mse))\n",
    "    print('### Test MSE:', np.mean(test_mse))\n",
    "    print('#' * 25)\n",
    "\n",
    "# # Averaging the Predictions of all Folds\n",
    "test_preds_all = test_preds_all.groupby(by=[\"Date\",\"Portion\"],as_index=False).mean()\n",
    "test_preds_all.to_csv(results_path+\"Test_Results.csv\",index=False)\n",
    "\n",
    "print(\"\\n\")\n",
    "print('#' * 25)\n",
    "print('### Avg Validation MSE:', np.mean(valid_mses))\n",
    "print('### Avg Test MSE:', np.mean(test_mses))\n",
    "print('#' * 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
